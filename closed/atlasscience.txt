* Context: Particle physics
  - (special) relativity and quantum mechanics: why (most of) particle physics follows from these two principles
    * properties ("quantum numbers") of particles: 
      energy
      momentum (4-momentum in relativstic)
      spin
      charge
    * interactions between particles,  
      interaction diagrams (not *quite* Feynman diagrams, but something more physically relevant), 
      the Standard Model and why it is almost inevitable
    * the universal experiment in particle physics: 
      scattering and < initial state | final state > transitions, 
      amplitudes and cross sections as observables
  - the Higgs boson
    * why it is necessary
    * why it is so mysterious (especially for theorists) and totally novel: 
      The Hierarchy Problem
    * what to do against this confusion: experiments!

* Context: ATLAS
  - context LHC: 
    a purpose-built machine for preparing the initial state
  - ATLAS: what is it: 
    * a measurement device for the final state
    * magnet
    * different detectors (what do they measure?)
      . pixel detector
      . tracker
      . ECAL
      . muon system
  - what does it measure
    * bending, speed, energy, momentum -> 
      precisely the fundamental properties from above!
      (but not the spin)
  - what is the data that comes out directly
    * triggering
    
* data analysis, or "doing everything in reverse":
  - Event reconstruction:
    * idea: build a higher-level representation of the event that retains the 
      important information that is needed later, remove low-level details of the detector      
    * track finding, jet clustering ("particle flow"): need to know what the 
      signatures of particles in the detector are
      . amount of bending
      . kinds of interactions with diff detectors
  - Calibration:
    * offline-calibration: remove obvious detector effects. 
      Example: jet energy scale calibration
    * how to calibrate from data alone? usually a combination of many factors: 
      . data from testbeam (isolated test of single detector element)
      . inter-detector calibration (e.g. jet energy works via ECAL and tracker!)
  - Simulation
    * why? need to know how certain physical processes show up at the end of the pipeline
      probabilistic! because quantum level is!
    * Monte Carlo event generation: 
      scattering amplitudes ("loops"), 
      detector simulation
    * data / simulation scale factors 
      (additional small corrections to remove residual differences between 
      the simulation and the real detector, also determined during the calibration)
    * systematic uncertainties of the calibration / reconstruction: 
      identify the detector DoF => model, parameters

  - Physics analysis and statistical modelling: up to know, everything was generic & 
    common for all of ATLAS, now let's get more specific
    * Example! (come back to the Higgs boson story from the beginning and explain how to do it in practice)
      + possible decay channels of the Higgs boson and how to measure them
    * event selection / classification
    * discriminants
    * extracting the results: the final fit and the role of histograms: "comparing simulation to reality"
    * what is the kind of code you write?
    
* Tools and languages
  - root
  - c++
  - DSLs :-)
  - should we mention the computing infrastructure? I.e. data storage, the LHC computing grid, ...
    
* what exactly are you working on these days?
  - effective field theories 
  -> a way to parametrise deviations from the Standard Model / can come back to the very beginning
